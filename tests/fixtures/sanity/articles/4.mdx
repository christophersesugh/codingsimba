---
id: "d4e5f6g7-h8i9-012344"
title: "Node.js Performance Optimization"
slug: "nodejs-performance"
createdAt: "2023-12-10T10:10:00Z"
categoryId: "cat-789"
authorId: "author-2"
featured: false
published: true
tags:
  - id: "tag-003"
  - id: "tag-004"
image: "https://img.freepik.com/free-photo/mesmerizing-view-silhouette-tree-savanna-plains-sunset_181624-28022.jpg?semt=ais_hybrid&w=740"
excerpt: "Practical techniques to optimize your Node.js applications including clustering, caching, and async best practices."
---

# Node.js Performance Optimization

Node.js applications can face performance bottlenecks that impact user experience and server costs. This comprehensive guide covers practical techniques to optimize your Node.js applications for better performance, scalability, and resource utilization.

## Understanding Node.js Performance

Node.js is built on Chrome's V8 JavaScript engine and uses an event-driven, non-blocking I/O model. Understanding these fundamentals is crucial for optimization:

- **Event Loop**: The heart of Node.js asynchronous operations
- **Single-threaded**: Main thread handles events, heavy computations can block
- **Non-blocking I/O**: Efficient handling of concurrent operations

## Profiling and Monitoring

Before optimizing, you need to measure and identify bottlenecks:

### Built-in Profiling

```javascript
// Enable profiling
node --prof app.js

// Generate readable output
node --prof-process isolate-0x....-v8.log > processed.txt
```

### Performance Monitoring

```javascript
const { performance, PerformanceObserver } = require("perf_hooks");

// Monitor function performance
function measurePerformance(fn, name) {
  return async (...args) => {
    const start = performance.now();
    const result = await fn(...args);
    const end = performance.now();
    console.log(`${name} took ${end - start} milliseconds`);
    return result;
  };
}

// Usage
const optimizedFunction = measurePerformance(expensiveOperation, "ExpensiveOp");
```

### Memory Usage Monitoring

```javascript
function logMemoryUsage() {
  const used = process.memoryUsage();
  console.log({
    rss: `${Math.round((used.rss / 1024 / 1024) * 100) / 100} MB`,
    heapTotal: `${Math.round((used.heapTotal / 1024 / 1024) * 100) / 100} MB`,
    heapUsed: `${Math.round((used.heapUsed / 1024 / 1024) * 100) / 100} MB`,
    external: `${Math.round((used.external / 1024 / 1024) * 100) / 100} MB`,
  });
}

setInterval(logMemoryUsage, 5000);
```

## Clustering and Load Balancing

Utilize multiple CPU cores with clustering:

```javascript
const cluster = require("cluster");
const numCPUs = require("os").cpus().length;

if (cluster.isMaster) {
  console.log(`Master ${process.pid} is running`);

  // Fork workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on("exit", (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died`);
    cluster.fork(); // Restart worker
  });
} else {
  // Worker process
  require("./app.js");
  console.log(`Worker ${process.pid} started`);
}
```

### PM2 for Production

```bash
# Install PM2
npm install -g pm2

# Start with clustering
pm2 start app.js -i max

# Monitor
pm2 monit

# Configuration file
```

```javascript
// ecosystem.config.js
module.exports = {
  apps: [
    {
      name: "my-app",
      script: "./app.js",
      instances: "max",
      exec_mode: "cluster",
      env: {
        NODE_ENV: "production",
      },
    },
  ],
};
```

## Caching Strategies

Implement effective caching to reduce computational overhead:

### In-Memory Caching

```javascript
const cache = new Map();

function memoize(fn, ttl = 60000) {
  return async (...args) => {
    const key = JSON.stringify(args);

    if (cache.has(key)) {
      const { value, timestamp } = cache.get(key);
      if (Date.now() - timestamp < ttl) {
        return value;
      }
      cache.delete(key);
    }

    const result = await fn(...args);
    cache.set(key, { value: result, timestamp: Date.now() });
    return result;
  };
}

// Usage
const cachedDbQuery = memoize(expensiveDbQuery, 300000); // 5 minutes
```

### Redis Caching

```javascript
const redis = require("redis");
const client = redis.createClient();

class RedisCache {
  async get(key) {
    try {
      const data = await client.get(key);
      return data ? JSON.parse(data) : null;
    } catch (error) {
      console.error("Cache get error:", error);
      return null;
    }
  }

  async set(key, value, ttl = 3600) {
    try {
      await client.setex(key, ttl, JSON.stringify(value));
    } catch (error) {
      console.error("Cache set error:", error);
    }
  }

  async del(key) {
    try {
      await client.del(key);
    } catch (error) {
      console.error("Cache delete error:", error);
    }
  }
}

// Usage
const cache = new RedisCache();

async function getCachedData(id) {
  const cacheKey = `user:${id}`;
  let data = await cache.get(cacheKey);

  if (!data) {
    data = await fetchUserFromDatabase(id);
    await cache.set(cacheKey, data, 1800); // 30 minutes
  }

  return data;
}
```

## Database Optimization

Optimize database interactions for better performance:

### Connection Pooling

```javascript
const mysql = require("mysql2/promise");

const pool = mysql.createPool({
  host: "localhost",
  user: "user",
  password: "password",
  database: "mydb",
  waitForConnections: true,
  connectionLimit: 10,
  queueLimit: 0,
  acquireTimeout: 60000,
  timeout: 60000,
});

async function queryDatabase(sql, params) {
  const connection = await pool.getConnection();
  try {
    const [rows] = await connection.execute(sql, params);
    return rows;
  } finally {
    connection.release();
  }
}
```

### Query Optimization

```javascript
// Bad: N+1 queries
async function getBadUserPosts() {
  const users = await User.findAll();
  for (const user of users) {
    user.posts = await Post.findByUserId(user.id);
  }
  return users;
}

// Good: Single query with joins
async function getGoodUserPosts() {
  return await User.findAll({
    include: [{ model: Post }],
  });
}

// Pagination for large datasets
async function getPaginatedUsers(page = 1, limit = 10) {
  const offset = (page - 1) * limit;
  return await User.findAndCountAll({
    limit,
    offset,
    order: [["created_at", "DESC"]],
  });
}
```

## Asynchronous Best Practices

Optimize async operations to prevent blocking:

### Async/Await vs Promises

```javascript
// Sequential (slower)
async function sequentialOperations() {
  const result1 = await operation1();
  const result2 = await operation2();
  const result3 = await operation3();
  return [result1, result2, result3];
}

// Concurrent (faster)
async function concurrentOperations() {
  const [result1, result2, result3] = await Promise.all([
    operation1(),
    operation2(),
    operation3(),
  ]);
  return [result1, result2, result3];
}

// Batch processing
async function batchProcess(items, batchSize = 10) {
  const results = [];

  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, i + batchSize);
    const batchResults = await Promise.all(
      batch.map((item) => processItem(item)),
    );
    results.push(...batchResults);
  }

  return results;
}
```

### Worker Threads for CPU-intensive Tasks

```javascript
const {
  Worker,
  isMainThread,
  parentPort,
  workerData,
} = require("worker_threads");

if (isMainThread) {
  // Main thread
  function runWorker(data) {
    return new Promise((resolve, reject) => {
      const worker = new Worker(__filename, { workerData: data });

      worker.on("message", resolve);
      worker.on("error", reject);
      worker.on("exit", (code) => {
        if (code !== 0) {
          reject(new Error(`Worker stopped with exit code ${code}`));
        }
      });
    });
  }

  // Usage
  async function heavyComputation(data) {
    try {
      const result = await runWorker(data);
      return result;
    } catch (error) {
      console.error("Worker error:", error);
      throw error;
    }
  }
} else {
  // Worker thread
  function intensiveTask(data) {
    // CPU-intensive computation
    let result = 0;
    for (let i = 0; i < data.iterations; i++) {
      result += Math.sqrt(i);
    }
    return result;
  }

  const result = intensiveTask(workerData);
  parentPort.postMessage(result);
}
```

## Memory Management

Prevent memory leaks and optimize memory usage:

### Avoiding Memory Leaks

```javascript
// Bad: Global variables
let globalCache = {};

// Good: Module-scoped with cleanup
class CacheManager {
  constructor() {
    this.cache = new Map();
    this.cleanupInterval = setInterval(() => {
      this.cleanup();
    }, 60000);
  }

  set(key, value, ttl = 300000) {
    this.cache.set(key, {
      value,
      expires: Date.now() + ttl,
    });
  }

  get(key) {
    const item = this.cache.get(key);
    if (item && item.expires > Date.now()) {
      return item.value;
    }
    this.cache.delete(key);
    return null;
  }

  cleanup() {
    const now = Date.now();
    for (const [key, item] of this.cache.entries()) {
      if (item.expires <= now) {
        this.cache.delete(key);
      }
    }
  }

  destroy() {
    clearInterval(this.cleanupInterval);
    this.cache.clear();
  }
}
```

### Stream Processing

```javascript
const fs = require("fs");
const { Transform } = require("stream");

// Bad: Loading entire file
```
