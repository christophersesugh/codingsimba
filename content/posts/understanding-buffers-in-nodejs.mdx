---
  title: understanding buffers in NodeJs
  slug: understanding-buffers-in-nodejs
  tags: javascript, nodejs
  thumbnail: https://cdn.codingsimba.com/buffers.jpeg
  description: In this article, we'll explore Buffers in Node.js, a fundamental concept for handling binary data. We'll cover what Buffers are, how to create them, and how to work with them in Node.js applications.
  videoId: 
  createdAt: 2024-04-03
  published: true 
---

A Buffer is a lot like a string, except that it is a sequence
of bytes instead of a sequence of characters. Node was created before
core JavaScript supported typed arrays and there was no
Uint8Array to represent an array of unsigned bytes. Node defined the
Buffer class to fill that need. Now that Uint8Array is part of the
JavaScript language, Node’s Buffer class is a subclass of Uint8Array.
What distinguishes Buffer from its Uint8Array superclass is that it is
designed to interoperate with JavaScript strings: the bytes in a buffer
can be initialized from character strings or converted to character
strings. A character encoding maps each character in some set of
characters to an integer. Given a string of text and a character
encoding, we can encode the characters in the string into a sequence of
bytes. And given a (properly encoded) sequence of bytes and a
character encoding, we can decode those bytes into a sequence of
characters. Node’s Buffer class has methods that perform both
encoding and decoding, and you can recognize these methods because
they expect an encoding argument that specifies the encoding to be used.

## Encodings

Encodings in Node are specified by name, as strings. The supported
encodings are:

### 1. utf8

It is the default when no encoding is specified.

UTF-8 stands for "Unicode Transformation Format - 8-bit." It's a widely used character encoding standard for representing text in electronic communication. Here's a breakdown of its key aspects:

**Purpose:**

- UTF-8 is a way to translate characters into a format computers can understand and store.
- It allows computers to handle a vast range of characters, including those from different languages and alphabets (e.g., Chinese, Arabic, Cyrillic).

**Functionality:**

- UTF-8 is a variable-length encoding system, meaning it uses one to four bytes to represent a single character.
- This flexibility allows it to efficiently represent a wide variety of characters while being backward compatible with ASCII (the older 7-bit encoding standard).
  - The first 128 characters of Unicode, which correspond to the ASCII characters, are encoded using a single byte in UTF-8.

**Benefits:**

- UTF-8 is the most popular character encoding standard on the web and in software development due to its:
  - **Wide compatibility:** Most modern software and operating systems support UTF-8.
  - **Efficiency:** It uses space efficiently for common characters while accommodating diverse languages.
  - **Flexibility:** It can represent a vast range of characters, making it suitable for global communication.

**Comparison with Unicode:**

- It's important to distinguish between UTF-8 and Unicode:
  - **Unicode:** A universal character set that assigns a unique code point to every character in every human language.
  - **UTF-8:** A specific encoding method that translates these Unicode code points into a format computers can understand and store.

### 2. utf16le

Two-byte Unicode characters, with little-endian ordering

"UTF-16LE" stands for "Unicode Transformation Format - 16-bit, Little Endian." It's a specific way of encoding Unicode characters, which is a universal character set encompassing a vast range of languages and symbols. Here's a breakdown:

**Understanding UTF-16:**

- **Base Encoding:** UTF-16 is a 16-bit character encoding, meaning it uses two bytes to represent a single character.
- **Variable Length:** It's a variable-length encoding, capable of representing over 1 million Unicode characters.
  - Characters within the "Basic Multilingual Plane" (BMP), which includes most common characters, are encoded using a single 16-bit code unit.
  - Characters outside the BMP require two 16-bit code units, called surrogates, to be represented.

**Endianness:**

- The "LE" in "UTF-16LE" refers to the byte order used to store the 16-bit code units.
  - **Little Endian:** In UTF-16LE, the least significant byte (LSB) of the code unit is stored first, followed by the most significant byte (MSB). This is the opposite of big-endian, where the MSB comes first.

**Comparison with Other Encodings:**

- **UTF-8:** Another popular Unicode encoding, UTF-8, uses a variable-length approach with 1 to 4 bytes per character, making it more efficient for common characters.
- **UTF-16BE:** This is the big-endian version of UTF-16, where the byte order is reversed compared to UTF-16LE.

**Usage and Considerations:**

- UTF-16LE is used in various contexts, including:
  - Windows operating systems internally.
  - Some programming languages like Java.
  - Certain file formats like PDF.
- However, due to potential byte order issues and complexity, UTF-8 is generally preferred for broader compatibility and efficiency.

**Key Points:**

- UTF-16LE is a specific way of encoding Unicode characters using 16-bit code units and little-endian byte order.
- It's distinct from UTF-8, another popular Unicode encoding, in terms of byte usage and efficiency.
- While used in certain contexts, UTF-8 is often preferred due to its wider compatibility and simpler structure.

### 3. latin1

"Latin1" refers to the **ISO/IEC 8859-1** character encoding standard, also known as **Latin-1**.

**Purpose:**

- Latin-1 is a system for representing text digitally, specifically designed for languages using the Latin alphabet, primarily Western European languages like English, French, Spanish, etc.

**Key Features:**

- **8-bit Encoding:** It uses one byte (8 bits) to represent each character, allowing for a total of 256 distinct characters.
- **Subset of ISO/IEC 8859:** Latin-1 is part of a larger set of ISO/IEC 8859 encodings, each catering to different writing systems.
- **Accented Characters and Symbols:** In addition to the basic Latin alphabet, Latin-1 includes accented characters like ç, ñ, and symbols like ©, £, etc.

**Comparison with Other Encodings:**

- **ASCII:** The first 128 characters of Latin-1 are identical to the US-ASCII standard, which only covers basic English characters and symbols.
- **UTF-8:** UTF-8 is another popular encoding standard that uses a variable-length approach (1 to 4 bytes per character) and can represent a much wider range of characters, including those from non-Latin alphabets.

**Usage and Considerations:**

- Latin-1 was widely used in the past, particularly in early internet applications and text-based systems.
- While still supported by most software and operating systems, it's gradually being superseded by UTF-8 due to its limitations:
  - Restricted character set: Latin-1 cannot represent characters outside the Western European alphabet.
  - Potential encoding issues: Different platforms might interpret certain characters differently, leading to display problems.

### 4. ascii

ASCII stands for **American Standard Code for Information Interchange**. It's a foundational character encoding standard used for electronic communication between computers.

**Purpose:**

- ASCII defines a way to represent text digitally, assigning a unique numerical code to each character. This allows computers to understand and process text data efficiently.

**Key Features:**

- **7-bit Encoding:** Originally, ASCII used 7 bits to represent each character, allowing for 128 distinct characters.
- **Basic Character Set:** These 128 characters include:
  - Uppercase and lowercase letters of the English alphabet (A-Z, a-z).
  - Numbers (0-9).
  - Punctuation marks (.,?!).
  - Control characters (used for non-printing functions like carriage return).

**Limitations:**

- Due to its limited character set, ASCII cannot represent characters outside the basic English alphabet and symbols.
- This has led to the adoption of other encodings like UTF-8, which can handle a much wider range of characters from various languages.

**Legacy and Relevance:**

- While not the dominant encoding standard anymore, ASCII remains important for historical reasons:
  - The first 128 characters of most modern encodings, including UTF-8, are identical to ASCII.
  - Many older software systems and protocols still rely on ASCII.

### 5. hex

"hex" refers to **hexadecimal encoding**, a way of representing binary data using a base-16 system.

**Base 16 System:**

- Unlike the decimal system we commonly use (base-10), hexadecimal uses 16 symbols to represent numbers.
- These symbols include the digits 0-9 and the letters A-F (or a-f).

**Encoding Binary Data:**

- Computers store data internally as binary digits (0s and 1s).
- Hexadecimal encoding provides a more human-readable representation of this binary data.
- Each byte (8 bits) of binary data is converted into two hexadecimal digits.

**Benefits of Hex Encoding:**

- **Compactness:** Hexadecimal is more concise than directly representing binary data. For example, the binary representation of the letter "a" is 01100001, while its hexadecimal equivalent is 61.
- **Human-friendliness:** Hexadecimal allows easier identification of patterns and errors within binary data compared to long strings of 0s and 1s.

**Applications of Hex Encoding:**

- **Data Security:** Hexadecimal is often used in cryptography to represent sensitive data like passwords or encryption keys.
- **File Editing:** Hexadecimal editors allow directly manipulating the raw binary data of files, useful for low-level debugging or data analysis.
- **Networking:** Hexadecimal is sometimes used in network protocols for data transmission.

**Key Points:**

- Hexadecimal encoding is a base-16 system for representing binary data in a more human-readable format.
- It uses 16 symbols (0-9, A-F) to represent each byte of data.
- Hex encoding offers compactness and easier identification of patterns compared to raw binary data.
- It finds applications in data security, file editing, and network protocols.

### 6. base64

Base64 is a group of binary-to-text encoding schemes used in computer programming. It essentially translates binary data (composed of 0s and 1s) into a format consisting of printable characters, making it suitable for transmission or storage in environments that only support text.

**Functionality:**

- Base64 works by taking the binary data and dividing it into groups of 6 bits.
- Each 6-bit group is then mapped to a specific character from a set of 64 unique characters.
- This set typically includes:
  - Uppercase and lowercase letters (A-Z, a-z)
  - Numbers (0-9)
  - Special characters like +, /, and = (depending on the specific base64 implementation)

**Benefits:**

- **Textual Representation:** Base64 encoding allows binary data to be represented as text, making it compatible with systems that can only handle text data.
- **Data Integrity:** The encoding scheme ensures that the original data remains intact during transmission or storage.

**Applications:**

- **Embedding Data in Text:** Base64 is commonly used to embed images, videos, or other binary data within text formats like HTML or CSS.
- **Email Attachments:** Older email protocols might not handle binary attachments directly. Base64 encoding helps transmit such attachments by converting them to a text-based format.
- **URL Encoding:** Some special characters in URLs need to be encoded using base64 to ensure proper transmission.
- **Data Security:** Base64 is sometimes used for basic data obfuscation, although it's not a secure encryption method.

**Points to Consider:**

- **Increased Data Size:** Base64 encoding typically increases the data size by approximately 33% compared to the original binary data.
- **Not Encryption:** While it can obscure data, Base64 encoding doesn't provide true encryption and shouldn't be relied upon for sensitive information.

## Buffer properties

### 1. `length`

returns the number of bytes in the buffer.

```javascript
const buf = Buffer.from("hello");
console.log(buf.length); // 5
```

### 2. `Buffer.poolSize`

returns the size of the pool used by the Buffer class to store temporary buffers that are used by the Buffer instances created using `Buffer.alloc()`.

```javascript
console.log(Buffer.poolSize); // 8192
```

## Buffer methods

### 1. `Buffer.alloc(size[, fill[, encoding]])`

Creates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled.

```javascript
const buf = Buffer.alloc(5);
console.log(buf); // <Buffer 00 00 00 00 00>
```

### 2. `Buffer.allocUnsafe(size)`

Creates a new Buffer of size bytes. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data.

```javascript
const buf = Buffer.allocUnsafe(5);
console.log(buf); // <Buffer 00 00 00 00 00>
```

### 3. `Buffer.allocUnsafeSlow(size)`

Creates a new Buffer of size bytes. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data.

```javascript
const buf = Buffer.allocUnsafeSlow(5);
console.log(buf); // <Buffer 00 00 00 00 00>
```

### 4. `Buffer.from(array)`

Creates a new Buffer containing the given JavaScript array.

```javascript
const buf = Buffer.from([1, 2, 3]);
console.log(buf); // <Buffer 01 02 03>
```

### 5. `Buffer.from(arrayBuffer[, byteOffset[, length]])`

Creates a new Buffer containing the given ArrayBuffer.

```javascript
const arr = new Uint16Array(2);
arr[0] = 5000;
arr[1] = 4000;

const buf = Buffer.from(arr.buffer);
console.log(buf); // <Buffer 88 13 a0 0f>
```

### 6. `Buffer.from(buffer)`

Creates a new Buffer containing the given Buffer.

```javascript
const buf1 = Buffer.from("hello");
const buf2 = Buffer.from(buf1);

console.log(buf2); // <Buffer 68 65 6c 6c 6f>

console.log(buf1 === buf2); // false
console.log(buf1.equals(buf2)); // true
console.log(buf1.toString()); // hello
console.log(buf2.toString("utf-8")); // hello
console.log(buf1.toString("hex")); // 68656c6c6f
// Notice how buf1.toString("hex") converts the buffer to a hexadecimal string
// of the buffer's actual content.
console.log(buf2.toString("base64")); // aGVsbG8=
console.log(buf1.toString("ascii")); // hello
```

68 in hexadecimal is 104 in decimal, 65 is 101, 6c is 108, and 6f is 111. When you convert these decimal values to ASCII characters, you get "hello".

And when you convert "hello" to base64, you get "aGVsbG8=".
Converting 68 to binary, you get 01001000, 65 is 01000001, 6c is 01101100, and 6f is 01101111. When you concatenate these binary values, you get 01001000 01000101 01101100 01101100 01101111. When you convert this binary value to hexadecimal, you get 68656c6c6f.
68 in ascii is h, 65 is e, 6c is l, and 6f is o. When you concatenate these values, you get hello.

::: info
Binaries are prepended with 0b, octals with 0o, and hexadecimals with 0x.
This tells the JavaScript engine that the number is in binary, octal, or hexadecimal format.
:::

```javascript
const buf = Buffer.from([0x68, 0x65, 0x6c, 0x6c, 0x6f]);
console.log(buf.toString()); //hello
```

### 7. `Buffer.from(string[, encoding])`

Creates a new Buffer containing the given string.

```javascript
const buf = Buffer.from("hello");
console.log(buf); // <Buffer 68 65 6c 6c 6f>
```

### 8. `Buffer.isBuffer(obj)`

Returns true if obj is a Buffer, false otherwise.

```javascript
console.log(Buffer.isBuffer(Buffer.from("hello"))); // true
console.log(Buffer.isBuffer({})); // false
```

### 9. `Buffer.isEncoding(encoding)`

Returns true if encoding is a valid encoding, false otherwise.

```javascript
console.log(Buffer.isEncoding("utf-8")); // true
console.log(Buffer.isEncoding("utf-16")); // false
```

### 10. `buf.compare(target[, targetStart[, targetEnd[, sourceStart[, sourceEnd]]]])`

Compares buf with target and returns a number indicating whether buf comes before, after, or is the same as target in sort order.

```javascript
const buf1 = Buffer.from("abc");
const buf2 = Buffer.from("abcd");

console.log(buf1.compare(buf2)); // -1
console.log(buf2.compare(buf1)); // 1
console.log(buf1.compare(buf1)); // 0
```

### 11. `buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])`

Copies data from a region of buf to a region in target even if the target memory region overlaps with buf.

```javascript
const buf1 = Buffer.from("hello");
const buf2 = Buffer.alloc(3);

buf1.copy(buf2);

console.log(buf2); // <Buffer 68 65 6c>
```

### 12. `buf.entries()`

Returns an iterator of `[index, byte]` pairs from the buffer.

```javascript
const buf = Buffer.from("hello");

for (const pair of buf.entries()) {
  console.log(pair); // [0, 104] [1, 101] [2, 108] [3, 108] [4, 111]
}
```

### 13. `buf.equals(otherBuffer)`

Returns true if buf and otherBuffer have the same bytes, false otherwise.

```javascript
const buf1 = Buffer.from("hello");
const buf2 = Buffer.from("hello");

console.log(buf1.equals(buf2)); // true
```

### 14. `buf.fill(value[, offset[, end]][, encoding])`

Fills buf with the specified value. If the offset and end are not specified, the entire buffer will be filled.

```javascript
const buf = Buffer.alloc(5);

buf.fill(1);

console.log(buf); // <Buffer 01 01 01 01 01>
```

### 15. `buf.includes(value[, byteOffset][, encoding])`

Returns true if value is found in buf, false otherwise.

```javascript
const buf = Buffer.from("hello");

console.log(buf.includes("h")); // true
console.log(buf.includes("o")); // true
console.log(buf.includes("a")); // false
```

### 16. `buf.indexOf(value[, byteOffset][, encoding])`

Returns the index of the first occurrence of value in buf, or -1 if value is not found.

```javascript
const buf = Buffer.from("hello");

console.log(buf.indexOf("h")); // 0
console.log(buf.indexOf("o")); // 4
console.log(buf.indexOf("a")); // -1
```

### 17. `buf.keys()`

Returns an iterator of the buffer's keys.

```javascript
const buf = Buffer.from("hello");

for (const key of buf.keys()) {
  console.log(key); // 0 1 2 3 4
}
```

### 18. `buf.lastIndexOf(value[, byteOffset][, encoding])`

Returns the index of the last occurrence of value in buf, or -1 if value is not found.

```javascript
const buf = Buffer.from("hello");

console.log(buf.lastIndexOf("h")); // 0
console.log(buf.lastIndexOf("o")); // 4
console.log(buf.lastIndexOf("a")); // -1
```

### 19. `buf.readBigInt64BE([offset])`

Reads an 8-byte signed integer from buf at the specified offset with big-endian encoding.

```javascript
const buf = Buffer.alloc(8);

buf.writeBigInt64BE(1n);

console.log(buf.readBigInt64BE()); // 1n
```

### 20. `buf.readBigInt64LE([offset])`

Reads an 8-byte signed integer from buf at the specified offset with little-endian encoding.

```javascript
const buf = Buffer.alloc(8);

buf.writeBigInt64LE(1n);

console.log(buf.readBigInt64LE()); // 1n
```

## Conclusion

In this article, we've covered the basics of Buffers in Node.js. Buffers are used to handle binary data in Node.js, and they are particularly useful when working with streams, file systems, and network operations. Understanding how to create, read, and manipulate Buffers is essential for building performant and efficient Node.js applications.
